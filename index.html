<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Voz con Retardo en Alta Calidad</title>
  <style>
    body { font-family: sans-serif; text-align: center; padding: 2em; background: #f0f0f0; }
    select, button { font-size: 1.2em; margin: 10px; padding: 10px; }
    .status { margin-top: 20px; font-weight: bold; }
  </style>
</head>
<body>
  <h1>üîÅ Voz con Retardo (Alta Calidad)</h1>
  <label for="delay">Retardo (segundos):</label>
  <select id="delay">
    <option value="1">1 segundo</option>
<option value="2">2 segundos</option>
<option value="3">3 segundos</option>
<option value="4">4 segundos</option>
<option value="5">5 segundos</option>
<option value="6">6 segundos</option>
<option value="7">7 segundos</option>
<option value="8">8 segundos</option>
<option value="9">9 segundos</option>
<option value="10">10 segundos</option>
<option value="11">11 segundos</option>
<option value="12">12 segundos</option>
<option value="13">13 segundos</option>
<option value="14">14 segundos</option>
<option value="15">15 segundos</option>
  </select><br>
  <button id="startBtn">üéôÔ∏è Iniciar</button>
  <button id="stopBtn" disabled>‚èπÔ∏è Detener</button>
  <div class="status" id="status">Esperando...</div>

  <script>
    let audioContext, sourceNode, delayNode, stream;
    const startBtn = document.getElementById("startBtn");
    const stopBtn  = document.getElementById("stopBtn");
    const delaySelect = document.getElementById("delay");
    const status = document.getElementById("status");

    startBtn.onclick = async () => {
      const d = parseInt(delaySelect.value);
      audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 48000 });

      stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 48000,
          channelCount: 1
        }
      });

      sourceNode = audioContext.createMediaStreamSource(stream);
      delayNode = audioContext.createDelay(15);
      delayNode.delayTime.setValueAtTime(d, audioContext.currentTime);
      sourceNode.connect(delayNode);
      delayNode.connect(audioContext.destination);

      status.textContent = `üéß Retardo activo: ${d} segundo(s)`;
      startBtn.disabled = true;
      stopBtn.disabled = false;
    };

    stopBtn.onclick = () => {
      stream.getTracks().forEach(t => t.stop());
      sourceNode.disconnect();
      delayNode.disconnect();
      audioContext.close();
      status.textContent = "‚èπÔ∏è Detenido.";
      startBtn.disabled = false;
      stopBtn.disabled = true;
    };
  </script>

  <canvas id="waveform" width="600" height="100" style="margin-top: 30px; background: white; border: 1px solid #ccc;"></canvas>

  <script>
    let analyser, dataArray, animationId;
    const canvas = document.getElementById("waveform");
    const ctx = canvas.getContext("2d");

    function drawWaveform() {
      analyser.getByteTimeDomainData(dataArray);
      ctx.fillStyle = "#fff";
      ctx.fillRect(0, 0, canvas.width, canvas.height);

      ctx.lineWidth = 2;
      ctx.strokeStyle = "#007acc";
      ctx.beginPath();

      const sliceWidth = canvas.width / dataArray.length;
      let x = 0;

      for (let i = 0; i < dataArray.length; i++) {
        const v = dataArray[i] / 128.0;
        const y = v * canvas.height / 2;

        if (i === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }

        x += sliceWidth;
      }

      ctx.lineTo(canvas.width, canvas.height / 2);
      ctx.stroke();

      animationId = requestAnimationFrame(drawWaveform);
    }

    startBtn.onclick = async () => {
      const d = parseInt(delaySelect.value);
      audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 48000 });

      stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 48000,
          channelCount: 1
        }
      });

      sourceNode = audioContext.createMediaStreamSource(stream);
      delayNode = audioContext.createDelay(15);
      delayNode.delayTime.setValueAtTime(d, audioContext.currentTime);

      analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      const bufferLength = analyser.fftSize;
      dataArray = new Uint8Array(bufferLength);

      sourceNode.connect(delayNode);
      delayNode.connect(audioContext.destination);
      sourceNode.connect(analyser);

      drawWaveform();

      status.textContent = `üéß Retardo activo: ${d} segundo(s)`;
      startBtn.disabled = true;
      stopBtn.disabled = false;
    };

    stopBtn.onclick = () => {
      stream.getTracks().forEach(t => t.stop());
      sourceNode.disconnect();
      delayNode.disconnect();
      analyser.disconnect();
      audioContext.close();
      cancelAnimationFrame(animationId);
      status.textContent = "‚èπÔ∏è Detenido.";
      startBtn.disabled = false;
      stopBtn.disabled = true;
    };
  </script>
</body>
</html>

</html>
